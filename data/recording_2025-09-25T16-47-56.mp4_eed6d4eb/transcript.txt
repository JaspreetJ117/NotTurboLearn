 I'm making sure I get some of the terminology here. So we're going to throw around the term random variable along this class. It's somewhat formal definition. It's something that can be used in an experiment. We'll often call it X. And then the distribution is a description of the behavior of the variable. But we always describe it somehow. So it's like a table, graph, or other description. So we have the possible values the variable can make on and the associated probabilities. So... So... So let's look at this. So let's... Let's take an example. So I'm going to do a simple example. We'll start with points. So we'll flip a point three times and we'll ask how many heads we get for the three points. And there's a couple ways to... There are a couple ways to... So there are... So there are eight different possible questions. Each point will be an average table. There are a number of words. There are all the different divisions. Then you can get three tails in a row. You can get tails out of seven. You can get tails out of ten tails. So that's a pretty good example. You can bring the group... And then over here I'm going to say what? X. I'm going to put X here. You can count them up. And you can even calculate the probability of this happening using the classical method from last week. Well, now we're going to put that board up over here. Behavior. So this is a classical method. It's classically a calculated probability. Any of them? Any of the number of times they happen? Population? This is behavior plus a state. Population times a state. So you've got eight rows in that table. Next, one of the discs over here is already a box there. That is a table that has the probability distribution of X over X. So this table is the probability distribution of X. So we're going to get back to the center of the moment. You can also graph X and do a classical histogram. Okay. So this is a probability function. And the formal name of this is actually a probability density function. We will start giving it a shorthand PDF. Not to be confused with Adobe's portable document format. As usual, we have this converse. PDF. Okay. So the probability density function of a distribution is a graph that shows how likely the results are. Usually turning it into a nice pretty curve of some kind. The thing about discrete functions is that discrete functions are made with these, like, bar graphs, essentially. I'll add that to the note. Note that discrete distributions look like bar graphs. This is distinct from continuous distribution, which we'll get to next week, which always look like curves or like calculus functions. Okay here. So this is the average deviation and variance of the distribution I made. So the probability. They have to be between 1 and 1. So those probabilities in my table there, those probabilities over there, those are the same probabilities. They all have to be between 1 and 1. And the probabilities have to add to them. So the sum of all values of x. So the sum of all the probabilities has to add to 1. If you don't have that, you don't have a probability distribution. You may have a case of that. You will note that I added my boot numbers there. Okay. So the other requirements are that the x-axis should be exhaustive, although this is redundant for the probabilities. The x-axis should be exhaustive, but this is the same as the probability that I added 1. If you don't miss anything, you probably added 1. If you miss something, you probably added 1. The x-axis should also be mutually exclusive. So those are the rules. The x-axis, the probability, the probability that you don't overlap with each other, the probabilities are that you're on 1, probably the last one. That's what I'm saying. You don't have a lot of time left. You need to read everything. You need some time to allow yourself to read. Next you need to need identification and variables, and that's all for you. So I'll give you a little example and then maybe you can even do your own unmarked homework. See if you can figure it out before we come back. We're done, right? You still teaching me? We have these x's, we have these theta x's. Okay. Okay, so you've heard about the average or the mean. It's all about the expectation of the variable. You write it once you start dealing with expectation, you write it as E of x. And E of x means the average. And it is the sum of what's called x of x, of theta x. Camera. And I said I'd give you a tiny little piece of homework to do. We have two minutes to write that up, so let's do that. Okay.