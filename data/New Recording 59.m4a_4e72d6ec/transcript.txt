 So I can have the participation link. I completely forgot about this class. I'm really sorry. So I didn't bear that a minute. So it's fine. If you haven't done it, do so today. That was for the previous week. And then what I will do is, every Wednesday in the newsfeed, I will just put up the participation survey link for the week that we've just completed. So try and answer as honestly as possible. And that's that. And then what are we going to cover today? I'm going to try and, well, I'm going to definitely cover research. I'm also going to delve into personality. But I don't want to fall too behind. So what might happen is, on Wednesday, I will try and cover learning. But then I'll record myself with whatever I miss, because I kind of want to be on pace with everyone else. And I don't want to rush through the things at the very end when you're talking about your midterm. But I'm not supposed to be recording. So I'll put it on. I'll say, you have a week. Look at it. And then I'll take off the recording so no one knows. All right. All right, so let's get right into it. So let's talk about the Paul Thorn effect. This is something you should definitely note. I know that there is a multiple choice question on this. So what is this effect? So this is when research participants change their behavior simply because they know that they know more. So it's not because of the experimental treatment, which you'll understand in a few minutes. It's just because they know that they're being studied. So they're going to change their behavior accordingly. So what this does is it highlights how psychological factors like feeling special or receiving attention, these can all influence results. And obviously, when it's influencing these results, these are not accurate results. These are not accurate conclusions about the effect of the independent variable. OK? So here's a particular study that I want you to think about. It was a workplace study. And it looked at a factory. And what the researchers wanted to do was they wanted to test whether increasing light would improve worker productivity. So these light bulbs, does it increase your worker productivity? So productivity did indeed increase. But surprisingly, it also went up when the lights were dimmed again. The real cause wasn't the lighting. It was actually the attention that workers were receiving from being part of that study. So they felt observed. They felt valued, which motivated them to perform better. So it wasn't the light. It was just the attention that they were receiving, as being participants in that particular study. So this actually demonstrates to us that the Hawthorne effect can actually take place. That how your study can in itself influence behavior, regardless of the actual experimental changes. So do we understand that? All right. Remember, the other way of doing research is using a correlational design. So what happens in a correlational design? So correlational research, these measures, they measure variables precisely. And they examine relationships. They examine associations between variables without introducing any sort of change in the research setting. So this kind of research actually tells us whether or not two variables are related. But it does not test. And this is the important thing that you have to know. It does not tell us whether or not there is a cause and effect put into place. And I will explain that in a few minutes. So it tells us whether or not two variables are associated. Are they related to one another? So stress and job satisfaction. Are they related? But it doesn't tell us cause and effect. What I mean by that is, does stress lead to job satisfaction or not? That's a distinction. They're related. But does one lead to another? OK. So there are several ways in which we can conduct correlational research. There is surveys and interviews, where we basically ask people directly about their experiences, their thoughts, their behaviors. But we can also use existing data. So this is things like records. Maybe it's reports. Maybe it's data sets that already exist. You can look into those as well to see patterns. OK? Does that make sense? Will you remember that distinction between correlational and experimental, which I'll tell you in a few minutes? But just remember with correlational, all you're doing is you're trying to establish a relationship or an association. Or maybe it's just to identify a pattern. What you're not doing is whether or not these two variables, what leads to what. So there's no cause and effect put into place. Does that make sense? Say yes or no. Yes. OK. Because my short answer, it has that. OK? All right. You have to remember that in order to apply it. OK. All right. Now let's talk about what happens in a correlational design. OK? So I think by now, or maybe you haven't, how many of us have taken stats? How many of us know what a correlation coefficient is? No one does. OK. Like a few hands. OK. All right. So a correlation coefficient is abbreviated as R, like that small symbol R. Right? It describes the statistical relationship between two variables. OK? And it can range from minus 1 to positive 1. OK? What a correlation coefficient does is it tells us the direction as well as the strength of the relationship. OK? So direction has to do with whether or not it's positive or negative. OK? Minus 1 refers to a perfectly negative relationship. And a positive 1 refers to a perfectly positive relationship. OK? So that's the first thing you have to remember, that the correlation coefficient tells us the direction of that relationship. Is it positive or is it negative? OK? Minus 1, perfectly negative. Minus a positive 1, perfectly positive. And then 0, if you get the numerical value of 0, that means there's no statistical relationship. OK? So let me explain this using an example. What is meant by a positive correlation? A positive correlation basically means that when you increase on one variable, increase a unit on one variable, it is associated with an increase in another variable. OK? So here's the thing. Let's take a attendance in class, right, and your grade on the midterm. OK? If we were to use a correlational design, we would basically be seeing the association between the two. We're not really seeing cause and effect. We're just seeing, are they related? Are they associated? OK? Attendance in class with grade on the midterm. So this is what a positive relationship is. The more you attend in class, so you're seeing an increase on one variable, the greater your grade will be on the midterm. You're seeing an increase on the other variable. These are associated with one another. Does that make sense? A negative one would be you see an increase on one, and that's associated with a decrease on the other. So the more you attend class, the less likely you are to do well on the midterm. That sounds pretty weird, right? But it can happen. It's an association. Just a minute. It's an association. It doesn't mean that it's cause and effect. What that means is there's no way for me to know. There's no research. I mean, it's hypothetical. There is research for this. But it's hypothetical. There's no way for me to know that attending class will lead you to have an A plus in on the midterm. Does that make sense? That's what an experiment does, not a correlational design. Yes? So just to make sure that a positive correlation is when, let's say, an increase in x causes an increase in y. Not causes an increase. It's associated. Associated. So what's the difference between associated and it causes? Causes is it leads to something. Associated is you don't know if it leads to it. It's just associated. Just statistically. Yeah, statistically, even just we don't have any experimental design put into place. So we don't really know if it leads to one thing. We just know they're associated. And then for a negative correlation, if x increases, y decreases. Yes. Statistically. Yes. If x increases, y decreases. They're associated. Does that make sense? Good. OK. So that's the direction. Now let's talk about the strength. The strength of a correlation is inferred from judging how compact something is on a scatter plot. OK. When it comes to the x and y values. The more compact it is, the stronger the correlation would be. OK. The less compact it is, the weaker the correlation it would be. So here are some. OK. So correlation. Let me just test you on this. OK. So r is the correlation coefficient. Here, do we have any correlation? Let's talk about direction first. Look at the values. r equals 0, r equals 70, r equals minus 70. So in the first case, when it comes to the two variables, draw satisfaction and draw performance, are they associated with one another? Yes or no? No. Good. Why? Who wants to take a stab? Yes. Looking at the coefficient alone, 0 means there's no thing. Exactly. There's no association. No. It starts with a, right? Anthony. No. Double A. Aiden. No. Aaron. Aaron. OK. All right. OK. OK, good, Aaron. OK, how about r equals 70? First of all, is there an association? Jenny. Jenny, right? Yes. Is it a positive or a negative? Why is it positive? Well, in the numbers. Good. Yeah, that's it. That's all you need to know. Right? Like, that's it. OK. How about r equals my own? Like, scream there. r equals minus 70. Adeny. Adeny? Adeny. Adeny, yes. There's a negative coefficient. Negative. Why? Well, the coefficient's negative. Exactly. Right? It's negative. OK. So that's that. So good. We understand the direction. Now let's look at the compactness. Remember what I said, the strength. It refers to how compact the numbers are. OK? So the more compact they are, the stronger it is. The weaker it is, the less compact it is, the weaker it is. So here is that strength of it. What do you think? Sweet. This is all we're going to say. No correlation. Why would you even give? How about with these two? They're almost the same. Yes? Um, numbers. Exactly. Right? That's it. That's all you're going to need to know. But there isn't a test. On the test, there isn't a question where it's asking you about the strength of it. So you don't really need to. It's so easy. I did such a good job of dumbing it down for you, but it's not on it. OK? But know that. OK? All right. Good. Now, let's talk about how the correlations should be. OK? So here are some correlations. Height and weight. Is it positively or negatively correlated? r equals 0.44. Positive. OK. Is it as close to plus 1? No. So is it a perfect one? OK. How about smoking and lung cancer within 25? Is it positive or negative? Positive. Closer to 1? No. Right? Closer to 0.1? No. OK. So you're probably wondering, like, well, OK, how do I go about assessing this? Right? Like, how do I deal with this? So the general rule of thumb when it comes to evaluating the size of correlation is basically what's written on the slide. OK? To get a perfect 1, or to get a perfect minus 1, is going to be so rare. It's going to be very, very rare. If you get something like that you see in a journal article, you can for sure go and do some research and find out if it's being fabricated or not. OK? For sure. It's rare. It's rare to get perfect 1 or minus 1. Yes? I was just wondering if there is anything that is typically more complex. There isn't, because there are other variables that go into place. So there isn't. OK? So what is our general rule? As scholars, what is it that we do? We say that if it's close to 0.50, right, whether it's positive or negative, it doesn't matter, it's considered to be strong. 0.30, considered to be moderate. 0.10, considered to be weak. But there's still correlations, right? There's still some association. So even weak correlations will be there. And they're actually very, I would say, in the realm of OVHR, they are very important, because they will, and you will learn this as you take more courses, hopefully, in this particular domain, that they could lead to costly behaviors and important outcomes. OK? But anyway, so let's now talk about correlation in a little bit more detail. OK? This I feel like you should definitely know. So correlation only tells us if there is a relationship or if there is an association between two variables. It tells you the direction of that relationship. It tells you the strength of that relationship. What it doesn't tell us is why that association exists. It does not tell us what causes what, what leads to what. So correlation is not enough to prove causation. So causation would be why does it exist and what leads to what. So making causal inferences requires ruling out alternative explanations, which you cannot do with a correlational design. So what comes into play here? Experimental designs. OK? They're used for that purpose. What happens in an experiment? Well, you'll learn about that in a week from today. But what happens is you control things. OK? You control factors that could actually create misleading correlations. OK? Let's take this as an example. You attended class, right? Getting a good grade. But what are some other things that might result in you getting a good grade? Studying for more hours. You study more hours. So that would be a reason why, right? What else? Who else wants to? You do the practice exams, right? OK, good. What else? You're taking notes in the lectures? You're taking notes. So there are a couple of different things that could go into place, right? Here are some other things that might have an effect. Maybe it's your race. So there's research that indicate that certain races are at a disadvantage for certain tests. Cognitive ability tests, you see certain races not doing well in them. There's an ample research to indicate that. So what I'm trying to say is that there are other factors that will be going to affect, but they are not measured at this stage. Does that make sense? So correlation does not equal causation. And that is something you need to drill in your head. Because that is the thing that is the key in the question that I will ask you. OK? Good. All right. So experimental design comes into place. I'm curious about this comment. I don't want to spend too much. Should I give you this example? OK, let's give this correlational research an example. OK, so here's the hypothesis. Employees who perceive their supervisors as friendly and considerate will be more productive than those who perceive their supervisors as unfriendly and inconsiderate. OK? So how can you go about testing this? Well, you can use a service. You can just ask people to talk about their supervisor. Are they friendly? Are they considerate? And then you can ask them how productive you feel and all that stuff. OK? So what do we find? OK? We find that it is correlated. Is it in a positive direction? What are your thoughts? It's planting upward, so it must be positive, right? What is the strength? Do you think this is a compact one? Yes, right? It is. OK. Good. Now, based on what we know, right? So there's a lot of correlations between the supervisor being friendly, considerate, and worker productivity. Based on this study, shouldn't an organization attempt to select only the friendly supervisors or train existing supervisors to be friendly to obtain higher productivity? What are your thoughts? Yeah? No, because there might be something going on under the hood that we don't know about. OK. Maybe they have better training. OK. And that leads them to perform better at their job instead of the supervisor being nice. Good. OK. What is your name? What's your name? My name? Eris. Eris. OK. Good. Anyone else have a point to add to that? Or maybe it's a different explanation. So maybe it's the training that they received. You haven't participated yet. Oh, yeah. It was very similar to that. No. Should I just tell you? Jaspreet. Jaspreet. Yeah. So I mean, the friendly supervisors exist because they had unfriendly supervisors in the first place, maybe. OK, sure. Yeah, because maybe in the first place, they experience the unfriendly supervisor. That's why they're like, oh, let me just be friendly. Yeah, so they might make a conscious effort to be friendly just because of their past experiences. OK, sure. All right. OK. All right, go on. So the way that the study was conducted, Jaspreet started that. And so the employees could have maybe influenced them a lot. Exactly, right? The employees, maybe they responded in such a way where it was not fabricated, but they exaggerated, right? Because maybe, who knows? They felt like their supervisor might be it, or whatever the case may be. OK, sure. If it's not a clear definition of what it means to be friendly, they might become too lenient. And they might drop productivity because they'll be like, oh, do whatever. Exactly, right? So again, it comes down. So as you can see, there's several. We can say this with affirmation. Yes, friendly supervisors will lead to productive workers. We simply can't. So that's where causation comes in. OK? So here, we cannot infer causation. We know they're associated, but there are other factors that might be playing, right? So the answer to that question is basically no. Why? Because the relationship is correlational, is not causal. Supervisors might be friendly if their employees are productive. We didn't consider that, right? So if all of you get A's in my class, I might be friendly as a result because of that. So it might be the other way around. Does that make sense? Yeah. So this is where a third variable problem comes in, meaning that there might be other factors explaining that relationship. So here is one. It could be positive work environment. It could be that. It could be a number of other things that you've already discussed. OK? So that's what you see in red is very important. Correlation does not mean causation. So how can we find out which factors cause these behaviors? Well, this is where the experimental design comes into play. OK? So what happens in an experiment? An experiment is like a test where it's a trial. OK? What we're doing is we want to see what happens when we change something. OK? So imagine that you're baking cookies. OK? And you want to know if adding more sugar will make them taste better. So basically what you would do is this. You would bake two batches of cookies. Right? In one would be the usual amount of sugar. And in the other one, you added extra sugar. Then you would taste both, and you'd compare. OK? That's an experiment right there. Does that make sense? So we have two conditions basically, two or more conditions, where we have changed the thing to see if it leads to it. OK? So in science or organizational studies, it's the same thing. We change one thing. This is called a variable. Right? We keep everything else the same. And then we see what happens. OK? We see if that change will make a difference. Will it lead to a different outcome? And this helps us figure out what causes what. Does that make sense? OK. So let's go back to that hypothesis of ours. Friendly supervision contributes to employee product. OK? So we want to find out if being supervised in a friendly way helps our employees work better, maybe become better productive, or be more productive. OK? So to test our hypothesis, which is basically like it said on the previous slide, friendly supervision contributes to employee productivity, we manipulate. That's a key thing here. We manipulate, or we change the level of friendliness in some supervisors. OK? So how might we be able to do that? Well, you could teach some supervisors to be considerate. You can teach them to be encouraging. You can teach them to be personable. It depends on your definition of friendliness, how you've defined it friendly. But you can teach some people to do that. And in the other condition, what you could do is you could just not teach them anything, or teach them the complete opposite. Teach them to be inconsiderate, not encouraging, not personable. OK? So then what we're going to do is there is a manipulation. There's a change. And we observe whether these employees become more productive. Compared to those who either didn't receive the training or who received the training in the opposite direction. Does that make sense? So that's the key thing with experimental design. Experimental design, you're manipulating something. OK? So if you want to test for something, your IV, you have two conditions to test your IV. To test your IV. OK? In one condition, you're actually doing what you want to set out. Like, if in this case it's friendly supervisor, train them to be friendly supervisor. And then in the other condition, you're doing the complete opposite, or they receive no training whatsoever. Usually, the best way is to give no training. Makes sense? And then you just see who's more productive. Is it those employees who receive the friendly training, or is it those who receive no training? Make sense? OK. So that's basically how you would go about doing this. Now, what is this particular graph showing you? OK. One of the questions that's often asked is, like, the friendly training, does it actually work? Right? Can we now confidently say that friendly supervisors lead to more productive employees? And it's not always necessarily the case. OK? Even if we see an increase in productivity, we can't be 100% sure that it was because of the friendly training. Maybe something else changed at the same time. Like, maybe new equipment was introduced, or maybe it was that the employees became more motivated, or maybe they're stressed because of, I don't know, maybe there are rumors of layoff. Who knows, right? So these are all called confounding errors. These are outside factors that might have influenced the result without us realizing it. OK? And so to control for that, we have a control group. What's a control group? Well, it's basically what I had described to you before. It's a group that was not exposed to the experimental treatment at all. OK? So in this case, it would be supervisors who didn't receive any sort of training. So why is this important? Why is it important to include a control group? It's important because in good experiment, we want to be confident that it's the treatment and just the treatment that caused the effect. OK? So that's why in a control group, we want everything to be the same, right? Like, we want the supervisors to be similar in age. We want them to have similar background. We want them to have similar experience. The only thing that should differ is the training that they received in one condition and in the other that they didn't. Because then you can say it with affirmation that, yes, it was the treatment that caused the effect. Does that make sense? So all else equal. That's why it led to that. So do we understand the difference between correlation and experimental? And do we understand how an experiment is conducted? Yes? Can I pick on someone to teach us how it stands? Because this is very important. So I want to, like, can I pick on someone? Who wants to volunteer? Yes, Simon? Basically, to conduct an experiment, you need a bunch of variables in one control group. Basically, what you want to do is you want to make sure that your environment is controlled. OK. Everything within the environment is the same. You have one thing to change. OK. So in the control group, you have a set base. Yes. And then in every other group, you change that base. OK. Good. And then you check the results of each group. Good. OK. But it won't be, on a test, it won't be like so many groups. It would just probably be like, just focus on this. There's two conditions, right? In one, you're manipulating. And in the other is a control. OK. And then what you explain is correct. OK. So in the control, you keep everything, basically everything stays the same. Everything stays the same. But in that one experimental treatment, you make that change that you're interested in. And then you look at the outcome. Make sense? OK. All right. Sorry. I already spoke about that. That's great. OK. Whatever. All right. Now let's talk about evaluating the quality of OB research. OK. The extent to which we don't actually provide the definition. Oh, I said it. Great. OK. Great. There we go. All right. The extent to which a researcher can be confident that changes in a dependent variable are due to the independent variable, and not by anything else, is known as internal validity. OK. In other words, what we're doing is we're actually asking ourselves, did the treatment really cause the effect? OK. And experiments usually tend to have higher internal validity. Why is that? Because the IV, the independent variable, is manipulated by the researcher. Right? There is strong control over other variables. And this is often, there is often a control group of comparison. OK. So this kind of setup, the experimental setup, what it does is it helps eliminate any of the confounding variables. OK. Other things that could have caused the outcome. We can be quite confident that the cause-effect relationship is real. So internal validity is really having to do with the experimental stuff. Did the treatment cause the effect? OK. The other one is known as external validity. External validity is all about whether the results of the study can be generalized or can be applied to the real world. OK. Real world, that means like other people, places, or times outside of the study. So basically, can we generalize these? And here's the thing. Correlational designs usually tend to have higher external validity and lower internal validity. Why? Why is it that correlations have higher external validity, lower internal validity? Well, there's a couple of different reasons. First, correlational, usually a survey or an interview that we've given to people. So they're often based on real world observations or surveys. They include naturally occurring variables, not manipulated ones. But having said that, since we can't really control or even randomly assign, which I'll talk about in a few minutes, we can't be sure what's causing what. OK? So does that make sense? Yes? No? All right. So in experiments, if there is no control group, internal validity would be low. Why? Because other factors might be explaining the dependent variable changes. In our case, it might be productivity. So what might these factors be? We've already discussed some. But maybe it's the selection of participants. So when participants, when they're selected for an experimental group, maybe they differ from those who are in the control group in some form or another. Maybe, I don't know. It could be a number of different things that could influence the experiment itself. Maybe it's the testing itself. Maybe the process of completing a survey and answering questions at the start of an experiment might sensitize participants to the study. It might influence how they respond to the questions after the experiment. So all in all, there might be a number of different factors that can go into it. And in order to address, in order to overcome the explanation of those different factors, we need to have a control group. Does that make sense? All right. So I already mentioned, here are some that you can make note of. OK, so we talked about that already. Let's talk about random sampling. So experimental studies use random sampling. In a well-designed experimental study, researchers often start with random sampling. So what this means is that they randomly choose participants from a larger population of interest. So by doing so, you're making sure that your sample is representative of the population that you're interested in, so that your results can be generalized beyond your own study. And of course, then, this will lead to external validity, which is, remember what it is. It's the ability to apply the findings to the real world. So in an experiment, how might random, so that's random sampling. So say I'm interested in university students. I'm interested in the same thing, my hypothesis, which would be, the more they attend class, the more likely they are to get an A on their test. So random sampling would be what? Which population should I be looking at, first of all? Students. Does it have to be from loop or Laurier? Doesn't have to be, but it can be, because you're students, much like every other. Should it be at the undergraduate level or master's level? What are your thoughts there? It depends on what I'm looking at. So if I'm saying undergrad, I should only be focusing my attention on undergrad, right? So it needs to be a little bit more specific. But that's what random sampling is, is to make sure you know your population and then to randomly select one. So I could send out a survey to almost all the universities and be like, I'm looking for second year organizational behavior students to complete my survey. That's it. That's random sampling. What happens after random sampling is random assignment. I don't think I mentioned that on this slide. No, I didn't. So note this down. So what happens is random assignment. So once you have selected your sample, the next important step is to randomly assign the participants to the groups. So you're randomly assigning them to the different groups. What are the two different groups? What are they called in an experiment? One is the? Control. Control. Control, good. The other one would be? Experimental. Experimental, treatments, manipulation, any of those. Any of those names. OK, makes sense? OK, good. So you randomly assign them. So remember, the experimental, manipulation, the treatment group, it receives the manipulation, the intervention. The control group does not receive it. So let me tell you what that means. So random assignment. So I now have conducted an experiment. This is my random class. It's a conflict of interest. But whatever. So this is my class. Randomly sampling this particular class. I want to see if you coming in for every class will result in a greater grade. That's my hypothesis. The more you attend class, the better your grade would be in the test. So how would I go about testing this? How about someone take a stab at this? Tell me how you would do this in an experimental class. Yes. I mean, for the control group, you could just let them be. And for the experimental group, we could offer them an incentive. Maybe give them a bonus mark for coming to class. Or like, you know. Yeah. You don't have to do that. It's a very safe. But you're good. OK. So the control group, let them be. Who wants to come? Who doesn't? For the other one, you make it mandatory for them to come to every class. It doesn't have to be associated with a bonus or anything. Do you see the difference between the two? Control is good. Let them be. Some people will show up for class. Some won't. It depends. Who cares? Other ones, you say to them, you need to show up for every class. So good. So we have an experimental group, which is like, come up for every class. And then we have a control. What would be my D.V.? What would be my D.V.? What is the outcome that I'm interested in? Yes, Aaron. The grade in the course. The grade in the course on the midterm. Right? OK, good. All right. So good. So we now have an experimental design put into place. So I randomly sampled this group for you. It's a random sample. Why I'm saying it's random sampling is because you are representative of all the second year OB students in Canada. OK? So that's random sampling. So now I have an experimental design. I have you come into the lab. Right? Now random assignment happens. So what does that mean? What does that mean? Yes, Aaron. Oh, specific people go into the lab? Yeah, but it's randomly done. What was your name, Aaron? Andrew. Andrew. OK. So Andrew's right. Specific people go into different groups. But how might that be? Maybe it's a draw. Maybe it's from a hat. Right? So Andrew comes in. Here's a hat. One says this condition. The other one says this condition. And that's how he's assigned. Or maybe I randomly assign you using a computer. Sort of like how I did the groups. Right? That was randomly assigning you to the groups. You don't know each other. I'm just like, here's the computer. Put them into groups. Same thing here. Makes sense? So do we understand that? Do we understand random assignment? Good. OK. So random assignment, what it does is it strengthens internal validity. OK? It helps make sure that the differences in the outcomes are likely due to the treatment and not other factors. Are likely due to the experimental manipulation and not other factors. Make sense? OK. So what's the main thing that I want you to take away from this? So tell me again. Between correlational and you're going to know the offer and effect. But between correlational and experimental. Tell me the main difference. Yes? Correlational is that there isn't a causal relationship with experimental. It can be all correlational. Exactly. That is the main thing. So in correlational, it only tells you whether or not there's an association or a relationship. It does not tell you what leads to what. So there's no cause and effect put into place. OK. So that's the first thing I want you to take away from this. And the second is just how to design an experimental design. So if something, if you need to design an experimental design, understand that there is a treatment or an experimental group, understand the fact that there is a control group, understand that you're going to randomly sample, also understand that there is going to be random assignment. Four key words. So remember this? Yes? Good. OK. All right. Now let's talk about ethics very quickly. Researchers, they have a moral and professional responsibility to basically conduct research vigorously and to report the findings truthfully. OK. They also have the moral and professional responsibility to protect the well-being of their participants. OK. So there are a couple of different things that go into play. So what are some key ethical principles when it comes to these? Well, you have to give them informed consent. So if you participated in the research, which you should have, like that long acronym, do we remember? Who is it? LR, L, RP, whatever. L is it, whatever it was. Make sure you're going to participate in those. You're going to get three marks, three percentages. So if you have gone through that already, you would have noticed that they actually give you a piece of paper at the very beginning for you to read and sign. Have you noticed that yet? How many of us have engaged in it? Jenny has. OK, a few of you have. I better see more hands next week. And then I don't want you to be in a position where you're like begging me for marks, so I'm going to shut it down. Right? So get those three percent. So next week, I better see more hands. Participate in the studies. OK. So the very first thing that you see is the informed consent. So what that happens is you're given a piece of paper and you are asked to read it. Basically, on this piece of paper, it says this is the purpose of the design or the study. This is what you will be doing in the next 45 minutes. Do I have your consent to give you this survey or to make you go through the experiment? So you need to sign it. That's the first thing that happens. We have to try and avoid unnecessary deception. So deception is used. What I mean by that is they might say to you that the purpose of this study is something, but in reality, they're looking for something else. Why might they use deception? It's because if you came to know the real reason for that study, you might act in a way that you think the researcher wants you to. I study forgiveness. I study apologies. If I outrightly say I'm looking at the effects of mindfulness on forgiveness, you will be like, oh my goodness, she needs the more mindful, the more forgiving. So I'm going to be more mindful because I'm going to be more forgiving. But if I deceive you and I say, hey, I'm actually looking at the effects of cognitive abilities on how people respond to unfair events, you will not. You will not be in that way. So avoid unnecessary deception. It can be used, but you really need to ask yourself, is there another way to go about it? Can I withhold information? In that situation, I just described to you where I would held information. That's different than deception. Yes. No? OK. I was going to say, that's basically just a multiple effect, right? Are you under? Yes. Yeah, because you're acting in a way that is expected of you. Yes. Yeah. OK. What are some other ethical principles? You need to ensure that you're anonymous, right? You also need to ensure confidentiality, OK? So basically, when you go into an experiment or when you conduct a study, all identifiers are removed, meaning you are not associated with that data. What I mean by that is it doesn't say, Jenny completed this survey, right? It doesn't say that just we conducted this experiment. All these identifiers are removed, OK? And it's confidential, right? What I mean by that is no one else should really know. Usually, how we do that is we present our findings in an aggregated format, OK? Volunteer participation is another key principle. What that means is people choose to join or leave at any time, OK? So you can choose to do the experiment. And while you're doing it, if you feel uncomfortable, you have every right to say, I'm sorry, I can't do this experiment anymore, OK? All right. And then there's no harm, no harm physically, psychologically, or emotionally, OK? So ethics isn't just about the rules. It's about respecting people. It's about protecting people. It's about protecting trust in research, OK? So what this one is telling us is this. So remember, there are three basic ways in which you can conduct research, right? There's observation. There's correlation. There's experimentation. Each come with their advantages and disadvantages, right? So experimentation tends to be more specific, but observation tends to be a little bit more rich, OK? So regardless, this is what I will say. A good researcher is one that uses a combination of different methods, OK? So they will have some observational designs. They will have some correlational design. They will have some experiments to show the same thing. So if I wanted to show that friendly supervisors lead to more productive workers, I will probably start off with observation. Then I would move on to correlational, and then I would do research or experiment. Make sense? Yes? OK, good. So that completes ethics, or sorry, that completes research. Do we have any questions about that? Let me now jump right into personality. So let me pull that up. I don't know why I'm feeling dizzy. It's warm, right? I'm still upset with that super-fed faculty member asking us to move on. I think that's why he asked us to move on, because he knew this would be a hot class. What are those? I don't know how to prove that. No, this is the transcription. We have to make the notes later with GPT. OK. Yeah, yeah, yeah. Do you have a thing for that one, or are you just going to put it in a chat GPT manager? Yeah, prompt right here. Just put the transcription here. We have to prompt. OK. Put it in chat GPT. Then it gives it a note. Oh, cancel that note, yeah. Yeah, I have a version with the GPT, it comes with notes, right? Yeah. But my PC can't run it. Here, I'll probably get it. I'll send it to you, so you can use it on yours. That's fine. All it does is it just gets a transcription or whatever, like of course a thing. OK. And now what we're going to do is we're going to talk about this now. We just give it the prompt. Oh, by the way, I got a lot of questions about this piercing text. Is it working now? Yeah. Yes. OK. It's my fault. I forgot to link it to the course. And then I read the message. Oh, I was supposed to link it. OK. It's not LL. OK. So let's talk about this. Let's talk about personality. So lots to cover here. I don't know how much I'm going to cover, but let's try to do this to the best of my ability. So I'm going to first talk about personality, why it matters to OV. We talk about the major OV debate, which is like, which approach is it? Is it positional, situational, and interactualist? And then I'm going to talk, I might not be able to do it, but we're going to talk about the five factor model of personality. And then there are other personality concepts. I'm not going to cover that, but I provided you with detailed slide notes. Detailed slides with possibly my notes. If you download it, I think my notes are on the bottom. It's just to help you for your midterm. These are probably going to be multiple choice questions, if at all. All right. So what is personality? So I always like to give this, but I've noticed that people don't like this. They don't understand what Gilbert is. So I think it's outdated. So here's a comment. It takes a certain type of personality to telecommunicate, dog bark. What? Just because other people have personalities doesn't mean you should try to develop one. And then dog bark, I don't think you'll understand it, because it's all my notes. Because I have a personality. And he's like, let's not get into that. Let's not get into that.